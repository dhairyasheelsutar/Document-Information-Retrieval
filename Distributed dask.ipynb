{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import joblib\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:62157\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>17.06 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:62157' processes=4 cores=4>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_project_matrix = dd.from_pandas(joblib.load(\"./models/tf_project_matrix.pkl\"), npartitions=1)\n",
    "tf_libs_matrix = dd.from_pandas(joblib.load(\"./models/tf_lib_matrix.pkl\"), npartitions=1)\n",
    "tf_frameworks_matrix = dd.from_pandas(joblib.load(\"./models/tf_framework_matrix.pkl\"), npartitions=1)\n",
    "tf_dbs_matrix = dd.from_pandas(joblib.load(\"./models/tf_dbs_matrix.pkl\"), npartitions=1)\n",
    "\n",
    "tf_projects = joblib.load(\"./models/tf_project.pkl\")\n",
    "tf_libs = joblib.load(\"./models/tf_lib.pkl\")\n",
    "tf_frameworks = joblib.load(\"./models/tf_framework.pkl\")\n",
    "tf_dbs = joblib.load(\"./models/tf_dbs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_based_feature_matrix = dd.from_pandas(joblib.load(\"./models/context_based_feature_matrix.pkl\"), npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary.load(\"./models/dictionary\")\n",
    "lda_model = LdaModel.load(\"./models/ldamodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_project_matrix = client.persist(tf_project_matrix)\n",
    "tf_libs_matrix = client.persist(tf_libs_matrix)\n",
    "tf_frameworks_matrix = client.persist(tf_frameworks_matrix)\n",
    "tf_dbs_matrix = client.persist(tf_dbs_matrix)\n",
    "context_based_feature_matrix = client.persist(context_based_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    with open(\"long_stopwords.txt\", \"r\") as fp:\n",
    "        stopwords_long = fp.read().split(\"\\n\")\n",
    "    common_stopwords = list(stopwords.words(\"english\"))\n",
    "    stopwords_list = list(set(stopwords_long + common_stopwords))\n",
    "    return stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stopwords()\n",
    "stop_words = stop_words + [\"input\", \"output\", \"fig\", \"database\", \"pict\", \"time\", \"paper\", \"description\", \"function\", \"class\", \"based\", \"process\", \"cid\", \"http\", \"www\", \"com\", \"electronics\", \"telecommunication\"]\n",
    "stop_words = stop_words + [\"project\", \"pict\", \"phase\", \"fulfillment\", \"partial\", \"requirements\", \"engineering\", \"pune\", \"bachelor\", \"submitted\", \"computer\", \"phule\", \"savitribai\", \"university\", \"degree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from dask_ml.metrics.pairwise import euclidean_distances\n",
    "import string\n",
    "import re\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tf-idf models\n",
    "\n",
    "client.publish_dataset(tf_project_matrix=tf_project_matrix)\n",
    "client.publish_dataset(tf_dbs_matrix=tf_dbs_matrix)\n",
    "client.publish_dataset(tf_libs_matrix=tf_libs_matrix)\n",
    "client.publish_dataset(tf_frameworks_matrix=tf_frameworks_matrix)\n",
    "client.publish_dataset(tf_dbs=tf_dbs)\n",
    "client.publish_dataset(tf_libs=tf_libs)\n",
    "client.publish_dataset(tf_projects=tf_projects)\n",
    "client.publish_dataset(tf_frameworks=tf_frameworks)\n",
    "\n",
    "# BERT and LDA Models\n",
    "\n",
    "client.publish_dataset(context_based_feature_matrix=context_based_feature_matrix)\n",
    "client.publish_dataset(id2word=id2word)\n",
    "client.publish_dataset(lda_model=lda_model)\n",
    "client.publish_dataset(stop_words=stop_words)\n",
    "\n",
    "# Dependencies\n",
    "\n",
    "client.publish_dataset(lemmatizer=lemmatizer)\n",
    "client.publish_dataset(word_tokenize=word_tokenize)\n",
    "client.publish_dataset(euclidean_distances=euclidean_distances)\n",
    "client.publish_dataset(string=string)\n",
    "client.publish_dataset(re=re)\n",
    "client.publish_dataset(da=da)\n",
    "client.publish_dataset(dd=dd)\n",
    "client.publish_dataset(np=np)\n",
    "client.publish_dataset(pd=pd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
